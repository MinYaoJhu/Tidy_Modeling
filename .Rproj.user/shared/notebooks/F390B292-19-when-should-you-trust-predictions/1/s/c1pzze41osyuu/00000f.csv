"0","#| echo = FALSE, "
"0","#| fig.width=6, "
"0","#| fig.height=6, "
"0","#| out.width=""70%"", "
"0","#| fig.align=""center"","
"0","#| fig.cap = ""Simulated two-class data set with a logistic regression fit and decision boundary."","
"0","#| fig.alt = ""Simulated two-class data set with a logistic regression fit and decision boundary. The scatter plot of the two classes shows fairly correlated data. The decision boundary is a parabola in the x axis that does a good job of separating the classes."""
"0",""
"0","data_grid <-"
"0","  crossing("
"0","    x = seq(-4.5, 4.5, length = 100),"
"0","    y = seq(-4.5, 4.5, length = 100)"
"0","  )"
"0","grid_pred <- "
"0","  predict(two_class_mod, data_grid, type = ""prob"") %>% "
"0","  bind_cols("
"0","    predict(two_class_mod, data_grid, type = ""pred_int"", std_error = TRUE),"
"0","    data_grid"
"0","  )"
"0",""
"0","grid_pred %>% "
"0","  mutate(`Probability of Class 1` = .pred_class_1) %>% "
"0","  ggplot(aes(x = x, y = y)) + "
"0","  geom_raster(aes(fill = `Probability of Class 1`)) +"
"0","  geom_point(data = testing_set, aes(shape = class, color = class), alpha = .75, size = 2.5) + "
"0","  geom_contour(aes(z = .pred_class_1), breaks = .5, color = ""black"", lty = 2) + "
"0","  coord_equal() + "
"0","  labs(x = ""Predictor x"", y = ""Predictor y"", color = NULL, shape = NULL) + "
"0","  scale_fill_gradient2(low = ""#FDB863"", mid = ""white"", high = ""#B2ABD2"", midpoint = .5) + "
"0","  scale_color_manual(values = c(""#2D004B"", ""darkorange""))"
