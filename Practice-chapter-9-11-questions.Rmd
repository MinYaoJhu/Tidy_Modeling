---
title: "Practice-chapter-9-11.Rmd"
author: "Min-Yao Jhu"
date: "2024-02-11"
output: 
  html_document: 
    keep_md: yes
---

We will practice using the Chicago data set on public transit ridership.  You can access it with:

```{r, eval=FALSE}
library(modeldata)
data("Chicago")
Chicago
```

Read about it with `?Chicago`; read more about it in [Kuhn and Johnson](https://bookdown.org/max/FES/chicago-intro.html)

```{r}
#?Chicago
```

```{r}
library(tidymodels)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(workflowsets)
library(kableExtra)
library(tidyr)
tidymodels_prefer()
```


## 1.  Explore the data

1. Make a histogram of ridership.  

```{r}
str(Chicago)
stations
```

> Ridership is measured by the number of entries into a station across all turnstiles, and the number of daily riders across stations during this time period varied considerably, ranging between 0 and 36,323 per day. 

> For ease of presentation, ridership will be shown and analyzed in units of thousands of riders.

```{r}
y_hist <- 
  ggplot(Chicago, aes(ridership)) +   
  geom_histogram(binwidth = .7, fill = "blue", col = "blue", alpha = .5) +
  xlab("Ridership (x1000 riders)")

y_hist
```

2. What might be causing the two peaks.  Is there a predictor variable that can account for this (or that can be used to make a new variable to account for it)?

I am not suggesting that you do regressions or plots on all variables at this time, rather that you think about what might have this kind of impact.

If you need to make a new predictor variable, go ahead.

```{r}
Chicago_week <- Chicago %>%
  mutate(dow = as.character(wday(ymd(date), label = T))) %>% 
  mutate(weekday = as.factor(ifelse(dow %in% c("Sat","Sun"), "Weekend", "Weekday"))) %>% 
  select(-c(date, dow))
Chicago_week

fig_Chicago_week <- 
  ggplot(Chicago_week, aes(ridership, fill = weekday, col = weekday)) + 
  facet_wrap( ~ weekday, nrow = 2, scales = "free_y") +
  geom_histogram(binwidth = .7, alpha = .5) +
  xlab("Ridership (x1000 riders)")
fig_Chicago_week
```

> A reasonable explanation for this would be that ridership is different for weekdays than for weekends. 

> This is important and necessary for explaining ridership and should be included in a model.

## 2. Training and Test

Make an 80/20 train/test split.  Do you need to stratify over anything?  

So that we are working on the same split, use `set.seed(010324)` in you code chunk

```{r}
set.seed(010324)

Chicago_split <- initial_split(Chicago_week, prop = 0.80, strata = ridership)
Chicago_train <- training(Chicago_split)
Chicago_test  <-  testing(Chicago_split)
```

```{r}
dim(Chicago_week)
dim(Chicago_train)
dim(Chicago_test)
```

## 3. Workflow set

Let's compare the effectiveness  of the temp and percip [sic] predictors.  

### 3A 

Use a workflow set (see chapter 7) to fit six models, each of which has your predictor from Q1 along with one of the following variables:

`temp_min`, `temp`, `temp_max`, `temp_change`, `percip`, `percip_max`

The formula for one of these would be something like `ridership ~ temp_min + Q1_predictor`.

```{r}
lm_model <- linear_reg() %>% set_engine("lm")
```

```{r}
weather <- list(
  temp_min = ridership ~ temp_min + weekday,
  temp = ridership ~ temp + weekday,
  temp_max = ridership ~ temp_max + weekday,
  temp_change = ridership ~ temp_change + weekday,
  percip = ridership ~ percip + weekday,
  percip_max = ridership ~ percip_max + weekday
)
```

```{r}
weather_models <- workflow_set(preproc = weather, 
                               models = list(lm = lm_model))
weather_models
```

```{r}
weather_models$info[[1]]
```

```{r}
extract_workflow(weather_models, id = "temp_lm")
```

```{r}
weather_models <-
   weather_models %>%
   mutate(fit = map(info, ~ fit(.x$workflow[[1]], Chicago_train)))
weather_models
```

### 3B 

Compare the model fits / predictors (this can be using any of the p-value of the predictor, R2, AIC, log-lik).  Don't worry about the test set, just compare goodness of fit when fit with the training set.

```{r}
weather_models %>%
  mutate(tidy=map(fit, tidy)) %>%
  unnest(tidy) %>%
  filter(str_detect(term, "temp|percip")) %>%
  arrange(p.value)
```


## 4 Recipes

### 4A

Create a workflow recipe does the following:

* normalizes all weather and station predictors
* creates a set of PCs for the weather-related predictors, keeping enough PCs to explain 75% of the variance in the weather variables
* creates a second set of PCs for the station-related predictors, keeping enough PCs to explaining 75% of the variance in these variables

Hint: `tidy()`, `prep()`, and `bake()` methods for recipes may be helpful in examining what you have done.  The help file on `recipe` is good to0.

Hint2: You can use various dplyr::select functions and regular expressions to avoid having to type out the variable names.  But as a fair-warning, it took me a lot longer to figure that out than it would have to just type then out.  (But next time it might be faster).  I can demo.

```{r}
recipe(ridership ~ ., data = Chicago_train) %>%
  add_role(Austin:California, new_role = "station") %>%
  add_role(temp_min:weather_storm, new_role = "weather")
```

```{r}
recipe(ridership ~ ., data = Chicago_train) %>%
  add_role(Austin:California, new_role = "station") %>%
  add_role(temp_min:weather_storm, new_role = "weather") %>%
  step_normalize(has_role("station")) %>%
  step_normalize(has_role("weather")) 
```
```{r}
recipe(ridership ~ ., data = Chicago_train) %>%
  add_role(Austin:California, new_role = "station") %>%
  add_role(temp_min:weather_storm, new_role = "weather") %>%
  step_normalize(has_role("station")) %>%
  step_normalize(has_role("weather")) %>%
  step_pca(has_role("station"), threshold = .75, prefix = "station_PC", id = "station_pca") %>%
  step_pca(has_role("weather"), threshold = .75, prefix = "weather_PC", id = "weather_pca")
```


```{r}
Chicago_rec <- 
  recipe(ridership ~ ., data = Chicago_train) %>%
  add_role(Austin:California, new_role = "station") %>%
  add_role(temp_min:weather_storm, new_role = "weather") %>%
  step_normalize(has_role("station")) %>%
  step_normalize(has_role("weather")) %>%
  step_pca(has_role("station"), threshold = .75, prefix = "station_PC", id = "station_pca") %>%
  step_pca(has_role("weather"), threshold = .75, prefix = "weather_PC", id = "weather_pca")

Chicago_rec
```

```{r}
tidy(Chicago_rec)
```


### 4B

Use the recipe from 4A to fit a linear regression of ridership on the new PCs and all remaining predictors (i.e. those not used in making the PCs).  Use the training data.

```{r}
lm_wflow <- 
  workflow() %>% 
  add_model(lm_model) %>% 
  add_recipe(Chicago_rec)

lm_fit <- fit(lm_wflow, Chicago_train)

tidy(lm_fit)

tidy(lm_fit) %>% select(term, p.value)
```

> remove date

> correlation between the 

### 4C

Use the fit from 4B to predict ridership in the test data.  Evaluate the predictions.

```{r}
str(Chicago_test)

Chicago_test_nor <- Chicago_test %>% select(-ridership)
str(Chicago_test_nor)

Chicago_test_onlyr <- Chicago_test %>% select(ridership,weekday)
str(Chicago_test_onlyr)
```

```{r}
predicted_r <- predict(lm_fit, Chicago_test_nor)
predicted_r
```

```{r}
chicago_test_predictions <- bind_cols(predicted_r, Chicago_test_onlyr)
chicago_test_predictions
```

```{r}
chicago_test_predictions |> 
  ggplot(aes(x = ridership, y = .pred, col = weekday)) + 
  geom_point(alpha = 0.5) +
  labs(y = "Predicted Ridership (x1000)", x = "Recorded Ridership (x1000)") +
  geom_smooth(method = lm, formula = y ~ x, color = "blue") +
  coord_equal()
```

Return to the Chicago data and Q4 from the previous Chicago assignment.

For Q4 we were predicting ridership from weather PCs, station PCs, and remaining predictors.

Use Cross-fold validation and the model selection techniques shown in chapter 12 to compare models with:

1. All PCs and remaining predictors (same as Q4)
optional: compare random forest and lm for this full data set

Step 1: Setting Up Cross-Fold Validation

```{r}
set.seed(123) # For reproducibility
cv_folds <- vfold_cv(Chicago_train, v = 10)
```

Step 2: Specifying Models

```{r}
# Linear Model Specification
lm_spec <- linear_reg() %>%
  set_engine("lm")

# Random Forest Specification
rf_spec <- rand_forest(trees = 1000) %>% 
  set_engine("ranger") %>% 
  set_mode("regression")
```

Step 3: Workflow and Model Comparison

```{r}
# Create workflows
lm_workflow <- 
  workflow() %>%
  add_model(lm_spec) %>%
  add_recipe(Chicago_rec)

rf_workflow <- 
  workflow() %>%
  add_model(rf_spec) %>%
  add_recipe(Chicago_rec)

# Compare models using cross-validation
keep_pred <- control_resamples(save_pred = TRUE, save_workflow = TRUE)

set.seed(1003)

lm_res <- 
  lm_workflow %>% 
  fit_resamples(resamples = cv_folds, control = keep_pred)

rf_res <- 
  rf_workflow %>% 
  fit_resamples(resamples = cv_folds, control = keep_pred)

collect_metrics(lm_res)
collect_metrics(rf_res)


```

```{r}
Chicago_rec1 <- 
  recipe(ridership ~ ., data = Chicago_train) %>%
  add_role(Austin:California, new_role = "station") %>%
  add_role(temp_min:weather_storm, new_role = "weather") %>%
  step_normalize(has_role("station")) %>%
  step_normalize(has_role("weather")) %>%
  step_pca(has_role("station"), threshold = .75, prefix = "station_PC", id = "station_pca") %>%
  step_pca(has_role("weather"), threshold = .75, prefix = "weather_PC", id = "weather_pca")

Chicago_rec1
```

2. The PCs + the weekend variable (no sports team data)

```{r}
str(Chicago_train)
```

use "update_role" to remove "sports_team" from predictors 

```{r}
Chicago_rec2 <- 
  recipe(ridership ~ ., data = Chicago_train) %>%
  update_role(Blackhawks_Away:Cubs_Home, new_role = "sports_team") %>%
  add_role(Austin:California, new_role = "station") %>%
  add_role(temp_min:weather_storm, new_role = "weather") %>%
  step_normalize(has_role("station")) %>%
  step_normalize(has_role("weather")) %>%
  step_pca(has_role("station"), threshold = .75, prefix = "station_PC", id = "station_pca") %>%
  step_pca(has_role("weather"), threshold = .75, prefix = "weather_PC", id = "weather_pca")

Chicago_rec2
```

3. 1 weather PC, 1 station PC, + the weekend variable

> select only the top 1 PC

```{r}
Chicago_rec3 <- 
  recipe(ridership ~ ., data = Chicago_train) %>%
  update_role(Blackhawks_Away:Cubs_Home, new_role = "sports_team") %>%
  add_role(Austin:California, new_role = "station") %>%
  add_role(temp_min:weather_storm, new_role = "weather") %>%
  step_normalize(has_role("station")) %>%
  step_normalize(has_role("weather")) %>%
  step_pca(has_role("station"), num_comp = 1, prefix = "station_PC", id = "station_pca") %>%
  step_pca(has_role("weather"), num_comp = 1, prefix = "weather_PC", id = "weather_pca")

Chicago_rec3
```

4. 1 weather PC + the weekend variable

use "update_role" to remove "station" from predictors 

```{r}
Chicago_rec4 <- 
  recipe(ridership ~ ., data = Chicago_train) %>%
  update_role(Blackhawks_Away:Cubs_Home, new_role = "sports_team") %>%
  update_role(Austin:California, new_role = "station") %>%
  add_role(temp_min:weather_storm, new_role = "weather") %>%
  step_normalize(has_role("weather")) %>%
  step_pca(has_role("weather"), num_comp = 1, prefix = "weather_PC", id = "weather_pca")

Chicago_rec4
```

5. 1 station PC + the weekend variable

use "update_role" to remove "weather" from predictors 

```{r}
Chicago_rec5 <- 
  recipe(ridership ~ ., data = Chicago_train) %>%
  update_role(Blackhawks_Away:Cubs_Home, new_role = "sports_team") %>%
  add_role(Austin:California, new_role = "station") %>%
  update_role(temp_min:weather_storm, new_role = "weather") %>%
  step_normalize(has_role("station")) %>%
  step_pca(has_role("station"), num_comp = 1, prefix = "station_PC", id = "station_pca") 

Chicago_rec5
```

6. the weekend variable only

use "update_role" to remove "weather" & "station" from predictors 

```{r}
Chicago_rec6 <- 
  recipe(ridership ~ ., data = Chicago_train) %>%
  update_role(Blackhawks_Away:Cubs_Home, new_role = "sports_team") %>%
  update_role(Austin:California, new_role = "station") %>%
  update_role(temp_min:weather_storm, new_role = "weather")

Chicago_rec6
```

```{r compare-workflow-set}
library(tidymodels)
tidymodels_prefer()

preproc <- 
  list(model1 = Chicago_rec1, 
       model2 = Chicago_rec2, 
       model3 = Chicago_rec3,
       model4 = Chicago_rec4,
       model5 = Chicago_rec5,
       model6 = Chicago_rec6
  )

lm_models <- workflow_set(preproc, list(lm = linear_reg()), cross = FALSE)
lm_models
```

```{r compare-workflow-set-resample}
lm_models <- 
  lm_models %>% 
  workflow_map("fit_resamples", 
               # Options to `workflow_map()`: 
               seed = 1101, verbose = TRUE,
               # Options to `fit_resamples()`: 
               resamples = cv_folds, control = keep_pred)
lm_models
```



```{r compare-workflow-set-collect}
collect_metrics(lm_models) %>% 
  filter(.metric == "rmse")
```

```{r compare-workflow-set-rsq}
library(ggrepel)
autoplot(lm_models, metric = "rsq") +
  geom_text_repel(aes(label = wflow_id), nudge_x = 1/8, nudge_y = 1/100) +
  theme(legend.position = "none")
```

```{r compare-collect}
rsq_indiv_estimates <- 
  collect_metrics(lm_models, summarize = FALSE) %>% 
  filter(.metric == "rsq") 

rsq_wider <- 
  rsq_indiv_estimates %>% 
  select(wflow_id, .estimate, id) %>% 
  pivot_wider(id_cols = "id", names_from = "wflow_id", values_from = ".estimate")

rsq_wider

#corrr::correlate(rsq_wider %>% select(-id), quiet = TRUE)
```

```{r compare-rsq-plot}
rsq_indiv_estimates %>% 
  mutate(wflow_id = reorder(wflow_id, .estimate)) %>% 
  ggplot(aes(x = wflow_id, y = .estimate, group = id, color = id)) + 
  geom_line(alpha = .5, linewidth = 1.25) + 
  theme(legend.position = "none")
```

1. All PCs and remaining predictors (same as Q4)
2. The PCs + the weekend variable (no sports team data)
3. 1 weather PC, 1 station PC, + the weekend variable
4. 1 weather PC + the weekend variable
5. 1 station PC + the weekend variable
6. the weekend variable only

Here is how I set up the weekend variable:

```{r}
#Chicago <- Chicago %>%
#  mutate(weekend = timeDate::isBizday(timeDate::as.timeDate(date)))
```

