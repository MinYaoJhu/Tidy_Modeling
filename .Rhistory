dim(ames_test)
str(ames_train)
str(ames_test)
#| fig.cap = "The distribution of the sale price (in log units) for the Ames housing data. The vertical lines indicate the quartiles of the data",
#| fig.alt = "The distribution of the sale price (in log units) for the Ames housing data. The vertical lines indicate the quartiles of the data."
sale_dens <-
density(ames$Sale_Price, n = 2^10) %>%
tidy()
quartiles <- quantile(ames$Sale_Price, probs = c(1:3)/4)
quartiles <- tibble(prob = (1:3/4), value = unname(quartiles))
quartiles$y <- approx(sale_dens$x, sale_dens$y, xout = quartiles$value)$y
quart_plot <-
ggplot(ames, aes(x = Sale_Price)) +
geom_line(stat = "density") +
geom_segment(data = quartiles,
aes(x = value, xend = value, y = 0, yend = y),
lty = 2) +
labs(x = "Sale Price (log-10 USD)", y = NULL)
quart_plot
set.seed(52)
# To put 60% into training, 20% in validation, and 20% in testing:
ames_val_split <- initial_validation_split(ames, prop = c(0.6, 0.2))
ames_val_split
ames_train <- training(ames_val_split)
ames_test <- testing(ames_val_split)
ames_val <- validation(ames_val_split)
library(tidymodels)
data(ames)
ames <- ames %>% mutate(Sale_Price = log10(Sale_Price))
set.seed(502)
ames_split <- initial_split(ames, prop = 0.80, strata = Sale_Price)
ames_train <- training(ames_split)
ames_test  <-  testing(ames_split)
knitr::opts_chunk$set(fig.path = "figures/")
library(tidymodels)
library(kknn)
library(kableExtra)
library(tidyr)
tidymodels_prefer()
source("ames_snippets.R")
parsnip_addin()
parsnip_addin()
knitr::opts_chunk$set(fig.path = "figures/")
library(tidymodels)
tidymodels_prefer()
source("ames_snippets.R")
library(tidymodels)
tidymodels_prefer()
# Set the random number stream using `set.seed()` so that the results can be
# reproduced later.
set.seed(501)
# Save the split information for an 80/20 split of the data
ames_split <- initial_split(ames, prop = 0.80)
ames_split
ames_train <- training(ames_split)
ames_test  <-  testing(ames_split)
dim(ames_train)
dim(ames_test)
str(ames_train)
str(ames_test)
#| fig.cap = "The distribution of the sale price (in log units) for the Ames housing data. The vertical lines indicate the quartiles of the data",
#| fig.alt = "The distribution of the sale price (in log units) for the Ames housing data. The vertical lines indicate the quartiles of the data."
sale_dens <-
density(ames$Sale_Price, n = 2^10) %>%
tidy()
quartiles <- quantile(ames$Sale_Price, probs = c(1:3)/4)
quartiles <- tibble(prob = (1:3/4), value = unname(quartiles))
quartiles$y <- approx(sale_dens$x, sale_dens$y, xout = quartiles$value)$y
quart_plot <-
ggplot(ames, aes(x = Sale_Price)) +
geom_line(stat = "density") +
geom_segment(data = quartiles,
aes(x = value, xend = value, y = 0, yend = y),
lty = 2) +
labs(x = "Sale Price (log-10 USD)", y = NULL)
quart_plot
set.seed(502)
ames_split <- initial_split(ames, prop = 0.80, strata = Sale_Price)
ames_train <- training(ames_split)
ames_test  <-  testing(ames_split)
dim(ames_train)
set.seed(52)
# To put 60% into training, 20% in validation, and 20% in testing:
ames_val_split <- initial_validation_split(ames, prop = c(0.6, 0.2))
ames_val_split
library(tidymodels)
data(ames)
ames <- ames %>% mutate(Sale_Price = log10(Sale_Price))
set.seed(502)
ames_split <- initial_split(ames, prop = 0.80, strata = Sale_Price)
ames_train <- training(ames_split)
ames_test  <-  testing(ames_split)
library(tidymodels)
data(ames)
ames <- ames %>% mutate(Sale_Price = log10(Sale_Price))
set.seed(502)
ames_split <- initial_validation_split(ames, prop = 0.80, strata = Sale_Price)
library(tidymodels)
data(ames)
ames <- ames %>% mutate(Sale_Price = log10(Sale_Price))
set.seed(502)
ames_split <- initial_validation_split(ames, prop = c(0.6, 0.2), strata = Sale_Price)
ames_train <- training(ames_split)
ames_test  <-  testing(ames_split)
set.seed(52)
# To put 60% into training, 20% in validation, and 20% in testing:
ames_val_split <- initial_validation_split(ames, prop = c(0.6, 0.2))
ames_val_split
ames_val_split <- initial_validation_split(ames, prop = c(0.6, 0.2), strata = Sale_Price)
ames_val_split
knitr::opts_chunk$set(fig.path = "figures/")
library(tidymodels)
library(kknn)
library(kableExtra)
library(tidyr)
tidymodels_prefer()
source("ames_snippets.R")
library(tidymodels)
tidymodels_prefer()
linear_reg() %>% set_engine("lm")
linear_reg() %>% set_engine("glmnet")
linear_reg() %>% set_engine("stan")
linear_reg() %>% set_engine("lm") %>% translate()
linear_reg(penalty = 1) %>% set_engine("glmnet") %>% translate()
linear_reg() %>% set_engine("stan") %>% translate()
lm_model <-
linear_reg() %>%
set_engine("lm")
lm_form_fit <-
lm_model %>%
# Recall that Sale_Price has been pre-logged
fit(Sale_Price ~ Longitude + Latitude, data = ames_train)
lm_xy_fit <-
lm_model %>%
fit_xy(
x = ames_train %>% select(Longitude, Latitude),
y = ames_train %>% pull(Sale_Price)
)
lm_form_fit
lm_xy_fit
arg_info <-
tribble(
~ `Argument Type`, ~parsnip,
"# trees", "trees",
"# sampled predictors", "mtry",
"# data points to split", "min_n"
)
arg_info <-
get_from_env("rand_forest_args") %>%
select(engine, parsnip, original) %>%
full_join(arg_info, by = "parsnip") %>%
mutate(package = ifelse(engine == "spark", "sparklyr", engine))
arg_info %>%
select(package, `Argument Type`, original) %>%
# mutate(original = paste0("<tt>", original, "</tt>")) %>%
pivot_wider(
id_cols = c(`Argument Type`),
values_from = c(original),
names_from = c(package)
) %>%
kable(
caption = "Example argument names for different random forest functions.",
label = "rand-forest-args",
escape = FALSE
) %>%
kable_styling() %>%
column_spec(2:4, monospace = TRUE)
arg_info %>%
select(`Argument Type`, parsnip) %>%
distinct() %>%
# mutate(parsnip = paste0("<tt>", parsnip, "</tt>")) %>%
kable(
caption = "Random forest argument names used by parsnip.",
label = "parsnip-args",
escape = FALSE
) %>%
kable_styling(full_width = FALSE) %>%
column_spec(2, monospace = TRUE)
rand_forest(trees = 1000, min_n = 5) %>%
set_engine("ranger") %>%
set_mode("regression") %>%
translate()
rand_forest(trees = 1000, min_n = 5) %>%
set_engine("ranger", verbose = TRUE) %>%
set_mode("regression")
lm_form_fit %>% extract_fit_engine()
lm_form_fit %>% extract_fit_engine() %>% vcov()
model_res <-
lm_form_fit %>%
extract_fit_engine() %>%
summary()
# The model coefficient table is accessible via the `coef` method.
param_est <- coef(model_res)
class(param_est)
param_est
tidy(lm_form_fit)
ames_test_small <- ames_test %>% slice(1:5)
predict(lm_form_fit, new_data = ames_test_small)
ames_test_small %>%
select(Sale_Price) %>%
bind_cols(predict(lm_form_fit, ames_test_small)) %>%
# Add 95% prediction intervals to the results:
bind_cols(predict(lm_form_fit, ames_test_small, type = "pred_int"))
tribble(
~ `Type of Prediction`, ~ `Returns a:`,
"numeric",                 "numeric matrix",
"class",                   "character matrix",
"probability (2 classes)", "numeric matrix (2nd level only)",
"probability (3+ classes)", "3D numeric array (all levels)",
) %>%
kable(
caption = "Different return values for glmnet prediction types.",
label = "predict-types"
) %>%
kable_styling(full_width = FALSE)
tribble(
~ `type value`, ~ `column name(s)`,
"numeric", ".pred",
"class", ".pred_class",
"prob", ".pred_{class levels}",
"conf_int", ".pred_lower, .pred_upper",
"pred_int", ".pred_lower, .pred_upper"
) %>%
kable(
caption = "The tidymodels mapping of prediction types and column names.",
label = "predictable-column-names",
) %>%
kable_styling(full_width = FALSE)  %>%
column_spec(1:2, monospace = TRUE)
tree_model <-
decision_tree(min_n = 2) %>%
set_engine("rpart") %>%
set_mode("regression")
tree_fit <-
tree_model %>%
fit(Sale_Price ~ Longitude + Latitude, data = ames_train)
ames_test_small %>%
select(Sale_Price) %>%
bind_cols(predict(tree_fit, ames_test_small))
lm_form_fit
str(lm_form_fit)
lm_form_fit$fit
lm_form_fit$fit
predict(lm_form_fit, new_data = ames_test_small)
predict(lm_form_fit$fit, new_data = ames_test_small)
predict(lm_form_fit$fit, new_data = ames_test_small)
ames_train
lm_model <-
linear_reg() %>%
set_engine("lm")
lm_form_fit <-
lm_model %>%
# Recall that Sale_Price has been pre-logged
fit(Sale_Price ~ Longitude + Latitude, data = ames_train)
lm_xy_fit <-
lm_model %>%
fit_xy(
x = ames_train %>% select(Longitude, Neighborhood),
y = ames_train %>% pull(Sale_Price)
)
lm_form_fit
lm_xy_fit
lm_model <-
linear_reg() %>%
set_engine("lm")
lm_form_fit <-
lm_model %>%
# Recall that Sale_Price has been pre-logged
fit(Sale_Price ~ Longitude + Neighborhood, data = ames_train)
lm_xy_fit <-
lm_model %>%
fit_xy(
x = ames_train %>% select(Longitude, Neighborhood),
y = ames_train %>% pull(Sale_Price)
)
lm_form_fit
lm_xy_fit
?ChickWeight
data(ChickWeight)
data(ChickWeight)
summary(ChickWeight)
skimr::skim(ChickWeight) #nicer summary
library(tidymodels)
library(kknn)
library(kableExtra)
library(tidyr)
skimr::skim(ChickWeight) #nicer summary
install.packages("skimr")
install.packages(c("bslib", "crosstalk", "deldir", "dplyr", "ggmap", "ggthemes", "gtools", "htmlwidgets", "httr2", "insight", "leiden", "Matrix", "R.utils", "Seurat", "SeuratObject", "shiny", "stringi", "stringr", "tinytex"))
install.packages(c("bslib", "crosstalk", "deldir", "dplyr", "ggmap", "ggthemes", "gtools", "htmlwidgets", "httr2", "insight", "leiden", "Matrix", "R.utils", "Seurat", "SeuratObject", "shiny", "stringi", "stringr", "tinytex"))
skimr::skim(ChickWeight) #nicer summary
ChickWeight
?ChickWeight
str(ChickWeight)
library(tidymodels)
library(kknn)
library(kableExtra)
library(tidyr)
?ChickWeight
data(ChickWeight)
summary(ChickWeight)
skimr::skim(ChickWeight) #nicer summary
str(ChickWeight)
split_by_Chick <-
ChickWeight %>%
group_nest(Chick)
split_by_Chick
# Group the data by Chick
chick_grouped <- ChickWeight %>%
group_by(Chick)
str(ChickWeight)
# Group the data by Chick
chick_grouped <- ChickWeight %>%
group_by(Chick)
# Create a simple random sample of Chick indices
set.seed(123)
chick_grouped
chick_indices <- initial_split(chick_grouped, prop = 0.8, strata = Diet) %>%
training() %>%
ungroup() %>%
select(Chick)
# Use the selected Chick indices to split the data
chick_train <- filter(chick_grouped, Chick %in% chick_indices$Chick)
chick_test <- anti_join(chick_grouped, chick_train, by = "Chick")
chick_train
chick_test
# Group the data by Chick
chick_grouped <- ChickWeight %>%
group_by(Chick)
chick_grouped
# Create a simple random sample of Chick indices
set.seed(123)
chick_indices <- initial_split(chick_grouped, prop = 0.8, strata = Diet) %>%
training() %>%
ungroup() %>%
select(Chick)
# Use the selected Chick indices to split the data
chick_train <- filter(chick_grouped, Chick %in% chick_indices$Chick)
chick_test <- anti_join(chick_grouped, chick_train, by = "Chick")
chick_train
chick_test
# Group the data by Chick
chick_grouped <- ChickWeight %>%
group_by(Chick)
chick_grouped
# Create a simple random sample of Chick indices
set.seed(123)
chick_indices <- initial_split(chick_grouped, prop = 0.8) %>%
training() %>%
ungroup() %>%
select(Chick)
# Use the selected Chick indices to split the data
chick_train <- filter(chick_grouped, Chick %in% chick_indices$Chick)
chick_test <- anti_join(chick_grouped, chick_train, by = "Chick")
chick_train
chick_test
# Drop the grouping for the final datasets
chick_train <- chick_train %>% ungroup()
chick_test <- chick_test %>% ungroup()
chick_indices
chick_grouped
chick_indices
# Use the selected Chick indices to split the data
chick_train <- filter(chick_grouped, Chick %in% chick_indices$Chick)
chick_train
chick_indices$Chick
Chick %in% chick_indices$Chick
ChickWeight$Chick
# Use the selected Chick indices to split the data
chick_train <- filter(chick_grouped, ChickWeight$Chick %in% chick_indices$Chick)
# Use the selected Chick indices to split the data
chick_train <- filter(chick_grouped$Chick %in% chick_indices$Chick)
# Use the selected Chick indices to split the data
chick_train <- chick_grouped |> filter(Chick %in% chick_indices$Chick)
# Use the selected Chick indices to split the data
chick_train <- chick_grouped |>
filter(Chick %in% chick_indices$Chick)
chick_train
chick_indices$Chick
chick_grouped$Chick
chick_indices$Chick
chick_indices <- initial_split(chick_grouped, prop = 0.8)
chick_indices
# Extract the training and test sets
chick_train <- training(chick_split)
chick_test <- testing(chick_split)
set.seed(123)
chick_indices <- initial_split(chick_grouped, prop = 0.8)
chick_indices
# Extract the training and test sets
chick_train <- training(chick_indices)
chick_test <- testing(chick_indices)
str(chick_train)
str(chick_train)
str(chick_test)
str(chick_train)
str(ChickWeight)
# Create a simple random sample of Chick indices
set.seed(123)
chick_indices <- group_initial_split(ChickWeight, prop = 0.8, strata = Diet)
# Create a simple random sample of Chick indices
set.seed(123)
chick_indices <- group_initial_split(ChickWeight, group = Chick, prop = 0.8, strata = Diet)
chick_indices
# Extract the training and test sets
chick_train <- training(chick_indices)
chick_test <- testing(chick_indices)
str(chick_train)
str(chick_test)
# Extract the training and test sets
chick_train <- training(chick_indices)
chick_test <- testing(chick_indices)
str(chick_train)
str(chick_test)
skimr::skim(chick_train)
skimr::skim(chick_test)
lm_model <-
linear_reg() %>%
set_engine("lme4")
parsnip_addin()
lm_model <-
linear_reg() %>%
set_engine("lm")
lm_form_fit <-
lm_model %>%
# Recall that Sale_Price has been pre-logged
fit(weight ~ diet + Time, data = chick_train)
lm_model <-
linear_reg() %>%
set_engine("lm")
lm_form_fit <-
lm_model %>%
# Recall that Sale_Price has been pre-logged
fit(weight ~ Diet + Time, data = chick_train)
lm_form_fit
lm_model <-
linear_reg() %>%
set_engine("lm")
lm_form_fit <-
lm_model %>%
# Recall that Sale_Price has been pre-logged
fit(weight ~ Diet * Time, data = chick_train)
lm_form_fit
tidy(lm_form_fit)
lm_model <-
linear_reg() %>%
set_engine("lm")
lm_form_fit1 <-
lm_model %>%
# Recall that Sale_Price has been pre-logged
fit(weight ~ Diet + Time, data = chick_train)
lm_form_fit1
tidy(lm_form_fit1)
lm_form_fit2 <-
lm_model %>%
# Recall that Sale_Price has been pre-logged
fit(weight ~ Diet * Time, data = chick_train)
lm_form_fit2
tidy(lm_form_fit2)
lmer_spec <-
linear_reg() %>%
set_engine("lmer")
lmer_fit <-
lmer_spec %>%
fit(weight ~ Time + (1|Diet), data = chick_train)
show_engines('linear_reg')
lmer_spec <-
linear_reg() %>%
set_engine("stan")
lmer_fit <-
lmer_spec %>%
fit(weight ~ Time + (1|Diet), data = chick_train)
install.packages("rstanarm")
lmer_spec <-
linear_reg() %>%
set_engine("stan")
lmer_fit <-
lmer_spec %>%
fit(weight ~ Time + (1|Diet), data = chick_train)
lmer_spec <-
linear_reg() %>%
set_engine("lmer")
lmer_fit <-
lmer_spec %>%
fit(weight ~ Time + (1|Diet), data = chick_train)
lmer_spec <-
linear_reg() %>%
set_engine("stan_glmer")
lmer_fit <-
lmer_spec %>%
fit(weight ~ Time + (1|Diet), data = chick_train)
library(multilevelmod)
install.packages("multilevelmod")
lmer_spec <-
linear_reg() %>%
set_engine("lmer")
lmer_fit <-
lmer_spec %>%
fit(weight ~ Time + (1|Diet), data = chick_train)
lmer_spec <-
linear_reg() %>%
set_engine("lm")
lmer_fit <-
lmer_spec %>%
fit(weight ~ Time + (1|Diet), data = chick_train)
lmer_spec <-
linear_reg() %>%
set_engine("lmer")
lmer_fit <-
lmer_spec %>%
fit(weight ~ Time + (1|Diet), data = chick_train)
parsnip_addin()
